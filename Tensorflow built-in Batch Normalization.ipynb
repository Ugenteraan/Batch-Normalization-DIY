{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import tensorflow as tf \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "epoch         = 5\n",
    "batch_size    = 200\n",
    "save_path     = './model_ckpt/model.ckpt'\n",
    "filename      = './60000'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readImages_hdf5(filename):\n",
    "    '''Reads hdf5 file.\n",
    "       Parameter\n",
    "       ---------\n",
    "       filename : the name of the hdf5 file\n",
    "    '''\n",
    "    file = h5py.File( filename + '.h5', \"r+\") #open the hdf5 file.\n",
    "    \n",
    "    hdf5_images = np.array(file[\"/images\"]).astype(\"uint8\") #read the images as np array\n",
    "    hdf5_labels = np.array(file[\"/meta\"]).astype(\"uint8\")\n",
    "    \n",
    "    return hdf5_images, hdf5_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoder(label_arr):\n",
    "    '''Returns the given MNIST labels from np arrays of integers to np array of one hot labels.\n",
    "       Parameter\n",
    "       ---------\n",
    "       label_arr : np array of MNIST integer labels\n",
    "    '''\n",
    "    total_labels  = label_arr.shape[0] #get the total number of labels\n",
    "    one_hot_label = np.zeros([total_labels, 10]) #10 for num of classes in MNIST\n",
    "    \n",
    "    for i in range(label_arr.shape[0]): #loop through all the labels\n",
    "        \n",
    "        one_hot_label[i][int(label_arr[i])] = 1.0 #the label value will be marked as 1.0 at that specific index\n",
    "        \n",
    "    return one_hot_label #returns the np one-hot label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = readImages_hdf5(filename)\n",
    "labels = one_hot_encoder(labels)\n",
    "images = images.reshape(images.shape[0],28, 28, 1) #reshape into a tensor of rank 4 for CNN filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "class Model():\n",
    "           \n",
    "    \n",
    "    def __init__(self):\n",
    "    \n",
    "        self.x = tf.placeholder(tf.float32, [None, 28,28,1], name='inputs')\n",
    "        self.y = tf.placeholder(tf.float32, [None, 10], name='targets')\n",
    "        self.is_train = tf.placeholder(tf.bool, name='is_train')\n",
    "\n",
    "        conv1 = tf.contrib.layers.conv2d(self.x, num_outputs=64, kernel_size=3, stride=1,padding='SAME', activation_fn=None)\n",
    "    \n",
    "        #batch normalization before the activation function but after the linear transformation.\n",
    "        conv1_norm = tf.layers.batch_normalization(conv1, training=self.is_train)\n",
    "        conv1_actv = tf.nn.relu(conv1_norm)\n",
    "\n",
    "        conv2 = tf.contrib.layers.conv2d(conv1_actv, num_outputs=64, kernel_size=3, stride=2,padding='SAME', activation_fn=None)\n",
    "        \n",
    "        #batch normalization before the activation function but after the linear transformation.\n",
    "        conv2_norm = tf.layers.batch_normalization(conv2, training=self.is_train)\n",
    "        \n",
    "        conv2_actv = tf.nn.relu(conv2_norm)\n",
    "        \n",
    "\n",
    "        output_size = 14*14*64\n",
    "        output_layer = tf.reshape(conv2_actv, (-1, output_size))\n",
    "\n",
    "\n",
    "        W2 = tf.Variable(tf.truncated_normal([output_size, 100], stddev=0.1))\n",
    "        B2 = tf.Variable(tf.ones([100]))\n",
    "\n",
    "        fc2 =  tf.add(tf.matmul(output_layer, W2), B2)\n",
    "        \n",
    "        #batch normalization before the activation function but after the linear transformation.\n",
    "        fc2_norm = tf.layers.batch_normalization(fc2, training=self.is_train)\n",
    "        fc2_actv = tf.nn.relu(fc2_norm)\n",
    "\n",
    "        W3 = tf.Variable(tf.truncated_normal([100, 10], stddev=0.1))\n",
    "        B3 = tf.Variable(tf.ones([10]))\n",
    "\n",
    "        self.logits = tf.add(tf.matmul(fc2_actv, W3), B3)\n",
    "\n",
    "        Y_pred = tf.nn.softmax(self.logits)\n",
    "    \n",
    "        self.loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=self.y, logits=self.logits))\n",
    "        \n",
    "        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS) #IMPORTANT\n",
    "        with tf.control_dependencies(update_ops): #IMPORTANT\n",
    "            self.optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(self.loss)\n",
    "        correct_prediction = tf.equal(tf.argmax(self.logits, 1), tf.argmax(self.y, 1))\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(correct_prediction, 'float'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the graph for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-6-841710c649c7>:47: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from ./model_ckpt/model.ckpt\n",
      "Model is not loaded !\n"
     ]
    }
   ],
   "source": [
    "model_cnn = Model()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "saver = tf.train.Saver(tf.global_variables())\n",
    "\n",
    "try:\n",
    "\n",
    "    saver.restore(sess, save_path)\n",
    "    print(\"Model has been loaded !\")\n",
    "\n",
    "except:\n",
    "\n",
    "    print(\"Model is not loaded !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss 64.8019, accuracy 0.948533\n",
      "Epoch 1, loss 14.0743, accuracy 0.9878\n",
      "Epoch 2, loss 7.84788, accuracy 0.994167\n",
      "Epoch 3, loss 4.45371, accuracy 0.997233\n",
      "Epoch 4, loss 2.38387, accuracy 0.999117\n"
     ]
    }
   ],
   "source": [
    "for epoch_idx in range(epoch):\n",
    "    \n",
    "    loss_total = 0\n",
    "    accuracy_total = 0\n",
    "    counter = 0\n",
    "    \n",
    "    for firstidx in range(0, images.shape[0], batch_size):\n",
    "        \n",
    "        finalidx = firstidx + batch_size\n",
    "        if finalidx >= images.shape[0] : finalidx = images.shape[0] #to prevent the index to be out of range.\n",
    "        \n",
    "        _, loss_val, accuracy_val = sess.run([model_cnn.optimizer, model_cnn.loss, model_cnn.accuracy], \n",
    "                                              feed_dict={\n",
    "                                                        model_cnn.x : images[firstidx:finalidx],\n",
    "                                                        model_cnn.y : labels[firstidx:finalidx],\n",
    "                                                        model_cnn.is_train : True\n",
    "                                                        })\n",
    "        loss_total += loss_val\n",
    "        accuracy_total += accuracy_val\n",
    "        counter += 1\n",
    "        \n",
    "    print(\"Epoch %d, loss %g, accuracy %g\"%(epoch_idx, loss_total, accuracy_total/counter))\n",
    "        \n",
    "    saver.save(sess, save_path)\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing session \n",
    "\n",
    "(Testing with the same trained data because the purpose is just to check if the estimated population mean and population variance works or not.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model_ckpt/model.ckpt\n",
      "Model has been loaded !\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "model_cnn = Model()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "saver = tf.train.Saver(tf.global_variables())\n",
    "\n",
    "try:\n",
    "\n",
    "    saver.restore(sess, save_path)\n",
    "    print(\"Model has been loaded !\")\n",
    "\n",
    "except:\n",
    "\n",
    "    print(\"Model is not loaded !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 2.38387, accuracy 0.999117\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "\n",
    "for firstidx in range(0, images.shape[0], batch_size):\n",
    "\n",
    "    finalidx = firstidx + batch_size\n",
    "    if finalidx >= images.shape[0] : finalidx = images.shape[0] #to prevent the index to be out of range.\n",
    "\n",
    "    loss_val, accuracy_val = sess.run([model_cnn.loss, model_cnn.accuracy], \n",
    "                                          feed_dict={\n",
    "                                                    model_cnn.x : images[firstidx:finalidx],\n",
    "                                                    model_cnn.y : labels[firstidx:finalidx],\n",
    "                                                    model_cnn.is_train : False\n",
    "                                                    })\n",
    "    \n",
    "    counter += 1\n",
    "\n",
    "print(\"Loss %g, accuracy %g\"%(loss_total, accuracy_total/counter))\n",
    "\n",
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nasa",
   "language": "python",
   "name": "nasa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
